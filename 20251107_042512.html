<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="stylesheet" href="_assets/style.css"><title>GitHub | collij22/yt- faceless -automation: Faceless YouTube Channel... — 20251107_042512</title></head><body><div class='wrapper'><a href='index.html'>&larr; Geri</a><div class='hero'><div class='tag'>Jarvis Autopilot</div><h1>GitHub | collij22/yt- faceless -automation: Faceless YouTube Channel... — 20251107_042512</h1><img src='../output/packages/20251107_042512/cover.png' alt='cover' /></div><h2>Makale</h2><p><h1>GitHub | collij22/yt- faceless -automation: Faceless YouTube Channel...</h1></p><p>Source: https://github.com/collij22/yt-faceless-automation</p><p>---</p><p>This repository provides a cutting-edge, profitability-focused automation system for faceless YouTube channels. It combines Claude Code subagents, Model Context Protocol (MCP) servers (Firecrawl, n8n MCP, Ref MCP), n8n workflows, and a lightweight Python 3.12 orchestration layer with FFmpeg-based video assembly.<br/>Citations used to derive strategy and implementation targets:<br/>- Faceless channel ideas and formats:<br/>[Zebracat — 13 Best Faceless YouTube Channel Ideas (2025)]- High-RPM niches:<br/>[TastyEdits — Most Profitable YouTube Niches in 2024]and[TubeBuddy — CPM & RPM expectations], plus community insight:[r/PartneredYoutube: Highest RPMs]- Trend sources:<br/>[Exploding Topics — AI Trends]- Upload automation:<br/>[n8n YouTube node docs]- Web research/scraping automation:<br/>[Firecrawl + n8n]and[Firecrawl MCP Server (GitHub)]- n8n MCP server:<br/>[LobeHub — n8n MCP Server]- Optional search API:<br/>[Brave Search API]and[What sets Brave apart]<br/>Each phase lists prerequisites and outputs, aligned with Claude Subagents best practices (<a href="https://docs.anthropic.com/en/docs/claude-code/sub-agents" target="_blank" rel="nofollow noopener">Anthropic docs — Subagents</a>).<br/>- Install: Python 3.12+, FFmpeg, Git.<br/>- Set up Claude Code with MCP servers:<br/>- Firecrawl MCP (scrape/search) — see<br/>docs/mcp-setup.md<br/>. - n8n MCP (or direct webhooks) — see<br/>docs/mcp-setup.md<br/>. - Ref MCP (latest docs retrieval; configure per your Ref MCP instructions) to keep all tool usage current.<br/>- Firecrawl MCP (scrape/search) — see<br/>- n8n instance: cloud or self-host; import workflows from<br/>workflows/<br/>. - Create<br/>.env<br/>from.env.example<br/>.<br/>Outputs:<br/>- Working dev environment, MCP servers connected, n8n workflows deployed.<br/>- Goal: pick niches with high RPM and strong demand, then generate a validated idea backlog.<br/>- Inputs: Zebracat ideas, TastyEdits RPM niches, TubeBuddy RPM data, Exploding Topics trends, Brave API (optional).<br/>- Subagents:<br/>research-analyst<br/>(uses Firecrawl MCP, optional Brave API). Produces 10–20 validated ideas with sources, keyword lists, and competitor notes.<br/>Outputs:<br/>data/ideas/*.json<br/>backlog with priority scores; SEO keyword sets per idea.<br/>- Subagent:<br/>scriptwriter<br/>applies high-retention structure (hook → promise → proof → preview → CTA → value → cliffhanger). Generates: script (with SSML markers for TTS), title variants, 500–1500 char description, tags, and chapter markers. - Validates against monetization and policy guardrails.<br/>Outputs:<br/>content/{slug}/script.md<br/>,metadata.json<br/>with titles/descriptions/tags/chapters.<br/>- Subagent:<br/>asset-curator<br/>fetches B‑roll and background using Firecrawl and stock sources.voiceover-producer<br/>compiles TTS via n8n webhook. - You can connect any TTS provider via n8n; keep costs low by batching and caching.<br/>Outputs:<br/>content/{slug}/audio.wav<br/>or.mp3<br/>,assets/<br/>with B‑roll lists and downloads,subtitles.srt<br/>(if generated).<br/>- Python + FFmpeg assembly provided in<br/>yt_faceless.assembly<br/>with CLIytfaceless assemble-timeline<br/>. - Subagent:<br/>video-assembler<br/>orchestrates assembly, transitions, background music, and subtitles. - Bulletproof Features (V4 visuals):<br/>- Openverse/Wikimedia compliant client:<br/>- Query sanitization; polite<br/>User-Agent<br/>with contact; Accept JSON; Commons downloads withReferer<br/>- 400/401/403/404 treated as non‑retry; 429 respects Retry‑After; per‑host concurrency and delays<br/>- Thumbnail‑first downloads for Commons; headered direct downloads with validation<br/>- Query sanitization; polite<br/>- Smart asset deduplication (perceptual hashing with URL fallback)<br/>- Automatic fallback gradient cards for scenes with no assets (pre‑generated pool)<br/>- FFprobe‑based audio duration sync and robust scene segmentation (monotonic timings)<br/>- Ken Burns on images and still‑frame holds (fps + tpad) for entire scene duration<br/>- Commercial license validation and attribution<br/>- Openverse/Wikimedia compliant client:<br/>Outputs:<br/>- Final<br/>content/{slug}/final.mp4<br/>with correct codecs and loudness.<br/>- Use n8n YouTube node to upload, schedule, set thumbnails, tags, chapters, and end screens.<br/>- Trigger via webhook from CLI<br/>ytfaceless publish<br/>or viauploader<br/>subagent.<br/>Outputs:<br/>- Scheduled YouTube video with SEO-optimized metadata.<br/>- Subagent:<br/>optimizer<br/>pulls analytics (CTR, APV, AVPV, retention curves) via n8n and proposes experiments (A/B titles/thumbnails, timestamps, descriptions). - Implement small weekly iteration cycles.<br/>Outputs:<br/>reports/*.md<br/>with experiments and next actions.<br/>- Subagent:<br/>revenue-analyst<br/>proposes affiliate integrations, sponsorship targets, Shorts repurposing, and content calendars. - Optional cross-posting flows (Reddit/Twitter/LinkedIn) per automation patterns (<br/><a href="https://www.reddit.com/r/automation/comments/1ltwvzg/autopost_about_trending_topics_with_your_ai_clone/" target="_blank" rel="nofollow noopener">r/automation autopost</a>).<br/>Outputs:<br/>- Monetization tracker, affiliate link management, sponsorship outreach list.<br/>python --version # 3.12+<br/>ffmpeg -version<br/><h1>Create and activate venv</h1><br/>py -3.12 -m venv .venv<br/>.venv\Scripts\activate<br/><h1>Install dependencies</h1><br/>pip install -e .[dev]<br/><h1>Configure environment</h1><br/>copy .env.example .env # Edit with your API keys<br/>The latest V4 pipeline generates properly sized videos with dynamic content:<br/><h1>Run the full production pipeline (default: sonnet model)</h1><br/>python run_full_production_pipeline_v4.py<br/><h1>Run with different AI models</h1><br/>python run_full_production_pipeline_v4.py --model claude # Comprehensive content<br/>python run_full_production_pipeline_v4.py --model haiku # Concise, viral-focused<br/>python run_full_production_pipeline_v4.py --model sonnet # Balanced (default)<br/>Key V4 Features:<br/>- ✅ Dynamic script length (1, 5, 10, or 30 minute videos)<br/>- ✅ No placeholders - all unique AI-generated content<br/>- ✅ Accurate timestamps matching actual video duration<br/>- ✅ Model selection for different content styles<br/>- ✅ Fresh idea generation (no recycling)<br/>- ✅ Bulletproof video assembly with automatic fallbacks and still‑image hold<br/>- ✅ Smart asset deduplication (perceptual or URL-based)<br/>- ✅ Commercial license compliance with attribution<br/>- ✅ YouTube-safe description length limits<br/>- ✅ Resilient API integration with retry logic<br/>When prompted:<br/>- Select video length (1/5/10/30 minutes) - script adjusts automatically<br/>- Choose niche (Finance/Tech/Health/Education)<br/>- Pick or create custom idea<br/>- Video generates at correct length (e.g., 5 min selection = 6 min video)<br/>ytfaceless init<br/>This will:<br/>- Create all required directories<br/>- Copy .env.example to .env (if needed)<br/>- Set up logging<br/>- Run initial health check<br/>- Configure environment<br/><h1>Edit .env with your API keys and webhook URLs</h1><br/>notepad .env<br/>-<br/>Configure MCP servers in Claude Code (see<br/>docs/mcp-setup.md<br/>). -<br/>Import n8n workflows from<br/>workflows/<br/>and set credentials (YouTube node per docs). -<br/>Verify configuration<br/>ytfaceless health # Run health check<br/>ytfaceless health --json # Get JSON output<br/>- Available CLI commands<br/>ytfaceless --help # Show all commands<br/>ytfaceless init # Initialize project<br/>ytfaceless health # Run health check<br/>ytfaceless assemble-timeline # Assemble video from visual timeline<br/>### Visual Enhancer (post‑V4)<br/>After `run_full_production_pipeline_v4.py` generates audio, the enhancer attaches visuals:<br/>.venv\Scripts\python.exe scripts\enhance_v4_visuals.py --slug YOUR_SLUG --parallel --burn-subtitles<br/>The enhancer will:<br/>- Plan/fetch assets (Openverse/Wikimedia) with compliant headers and backoff<br/>- Generate a robust visual timeline; if APIs fail, synthesize a minimal fallback timeline<br/>- Assemble the final video with Ken Burns and steady per‑scene still holds<br/>.<br/>├─ src/yt_faceless/<br/>│ ├─ __init__.py<br/>│ ├─ cli.py<br/>│ ├─ config.py<br/>│ ├─ logging_setup.py<br/>│ ├─ assembly.py<br/>│ ├─ youtube_metadata.py<br/>│ └─ orchestrator.py<br/>├─ tests/<br/>│ ├─ test_assembly.py<br/>│ └─ test_config.py<br/>├─ .claude/agents/<br/>│ ├─ research-analyst.md<br/>│ ├─ scriptwriter.md<br/>│ ├─ asset-curator.md<br/>│ ├─ voiceover-producer.md<br/>│ ├─ video-assembler.md<br/>│ ├─ uploader.md<br/>│ ├─ optimizer.md<br/>│ └─ revenue-analyst.md<br/>├─ workflows/<br/>│ ├─ tts_webhook_PRODUCTION.json<br/>│ ├─ youtube_upload_PRODUCTION.json<br/>│ ├─ youtube_analytics_PRODUCTION.json<br/>│ ├─ cross_platform_PRODUCTION.json<br/>│ └─ affiliate_shortener_PRODUCTION.json<br/>├─ docs/<br/>│ └─ mcp-setup.md<br/>├─ archive/<br/>│ ├─ run_full_production_pipeline.py<br/>│ ├─ run_full_production_pipeline_v2.py<br/>│ ├─ run_full_production_pipeline_v3.py<br/>│ ├─ claude_script_generator.py<br/>│ ├─ claude_script_generator_v2.py<br/>│ ├─ claude_script_generator_v3.py<br/>│ └─ assorted legacy tests/docs<br/>├─ .env.example<br/>├─ pyproject.toml<br/>├─ README.md<br/>└─ .gitignore<br/>Legacy V1–V3 pipelines, generators, and ad‑hoc tests have been moved to archive/<br/>. They are kept for reference only and should not be used in production. Use run_full_production_pipeline_v4.py<br/>exclusively.<br/>- Follow Conventional Commits for your commits.<br/>- Keep costs low by batching TTS and preferring efficient providers. Use Firecrawl to compile research summaries instead of scraping full pages when possible.<br/>- Always consult Ref MCP for latest docs before changing tool usage or APIs.</p><h2>Playbook</h2><p><h1>Playbook</h1></p><p><h2>Summary</h2></p><p>This repository provides a cutting-edge, profitability-focused automation system for faceless YouTube channels. It combines Claude Code subagents, Model Context Protocol (MCP) servers (Firecrawl, n8n MCP, Ref MCP), n8n workflows, and a lightweight Python 3.12 orchestration layer with FFmpeg-based video assembly. Citations used to derive strategy and implementation targets: - Faceless channel ideas and formats:</p><p><h2>Steps</h2></p><p>1. Each phase lists prerequisites and outputs, aligned with Claude Subagents best practices (<a href="https://docs.anthropic.com/en/docs/claude-code/sub-agents" target="_blank" rel="nofollow noopener">Anthropic docs — Subagents</a>).<br/>2. - Install: Python 3.12+, FFmpeg, Git.<br/>3. . - Ref MCP (latest docs retrieval; configure per your Ref MCP instructions) to keep all tool usage current.<br/>4. - Working dev environment, MCP servers connected, n8n workflows deployed.<br/>5. - Goal: pick niches with high RPM and strong demand, then generate a validated idea backlog.<br/>6. - Inputs: Zebracat ideas, TastyEdits RPM niches, TubeBuddy RPM data, Exploding Topics trends, Brave API (optional).<br/>7. (uses Firecrawl MCP, optional Brave API). Produces 10–20 validated ideas with sources, keyword lists, and competitor notes.<br/>8. backlog with priority scores; SEO keyword sets per idea.<br/>9. with titles/descriptions/tags/chapters.<br/>10. compiles TTS via n8n webhook. - You can connect any TTS provider via n8n; keep costs low by batching and caching.<br/>11. (if generated).<br/>12. with correct codecs and loudness.</p><div class='footer'>Generated by Jarvis</div></div></body></html>